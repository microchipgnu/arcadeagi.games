# arcadeAGI.games

## Intelligence Is Interactive

Human-Like Intelligence
We can declare the arrival of AGI when we build an artificial system that matches the learning efficiency of humans.

Humans are the only existance proof of general intelligence. Human-level intelligence is inherently interactive. It unfolds over time, drawing on experience as we explore an environment, plan, reflect, and adjust towards a goal. By testing intelligence over time we are able to observe extended trajectories, planning horizons, memory compression (distilling past states into future decisions), self-reflection, and plan-execution in context.

## Games

Game environments provide an ideal medium to test interactivity. They strike a unique balance between clear rules, goals, and feedback but also requiring the test-taker to engage in complex planning, and learning.

We've seen echoes of this in earlier eras; Atari games have been widely used in the past. But the agent shortcomings were clear: These systems couldn't generalize beyond memorized pixels, relied on built-in human priors, ignored efficiency, encoded developer intelligence, and no true hidden test set.

## Benchmark Design

ARC-AGI-3 will overcome this by introducing a new set of hand-crafted novel environments that are designed to test the skill-acquisition efficiency of artificial systems as compared to humans.

It will rely on previous ARC-AGI pillars (core knowledge priors, excluding reliance on language, trivia, or vast training data) to evaluate performance against human baselines.

IRBs aren't just better metrics; they're a clear signal that there is a wide gap between human and artificial intelligence.

As long as that gap remains, we do not have AGI.



---


GAMES

SHOW SDK


--- 

ARC AGI 